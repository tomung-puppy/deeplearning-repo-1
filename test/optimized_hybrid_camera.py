#!/usr/bin/env python3
"""
ÏµúÏ†ÅÌôîÎêú ÌïòÏù¥Î∏åÎ¶¨Îìú Ïπ¥Î©îÎùº Ïï± (ÎîîÎ≤ÑÍ∑∏ Î∞ïÏä§ Ìè¨Ìï®)
- cv2.imshow()Î•º Î©îÏù∏ Ïä§Î†àÎìúÏóêÏÑú Ï≤òÎ¶¨
- ÏõπÏ∫†ÏóêÏÑú ÏÉÅÌíà Ïù∏Ïãù Î∞îÏö¥Îî© Î∞ïÏä§ ÌëúÏãú
"""
import cv2
import time
import threading
import sys
from pathlib import Path
from queue import Queue

# ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏Î•º Python Í≤ΩÎ°úÏóê Ï∂îÍ∞Ä
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from network.udp_handler import UDPFrameSender
from common.config import config
from utils.image_proc import ImageProcessor
from detectors.product_dl import ProductRecognizer
from detectors.obstacle_dl import ObstacleDetector


class OptimizedHybridCameraApp:
    """ÏµúÏ†ÅÌôîÎêú ÌïòÏù¥Î∏åÎ¶¨Îìú Ïπ¥Î©îÎùº Ïï±"""

    def __init__(self, front_cam_id=2, cart_cam_id=0):
        if config is None:
            raise RuntimeError("Configuration could not be loaded. Exiting.")

        # Get config values
        main_hub_ip = config.network.pc2_main.ip
        front_cam_port = config.network.pc2_main.udp_front_cam_port
        cart_cam_port = config.network.pc2_main.udp_cart_cam_port

        # Camera resolution and FPS
        self.img_width, self.img_height = config.app.camera.resolution
        self.fps = config.app.camera.fps

        # UDP Senders
        self.front_sender = UDPFrameSender(main_hub_ip, front_cam_port, jpeg_quality=70)
        self.cart_sender = UDPFrameSender(main_hub_ip, cart_cam_port, jpeg_quality=70)

        # Front Webcam
        self.front_cam_id = front_cam_id
        self.front_cap = cv2.VideoCapture(front_cam_id)
        if not self.front_cap.isOpened():
            raise RuntimeError(f"Cannot open front webcam (device {front_cam_id})")

        # ÏõπÏ∫† Ìï¥ÏÉÅÎèÑ ÏÑ§Ï†ï
        self.front_cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.front_cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        self.video_interval = 1.0 / self.fps

        # Cart Webcam
        self.cart_cam_id = cart_cam_id
        self.cart_cap = cv2.VideoCapture(cart_cam_id)
        if not self.cart_cap.isOpened():
            raise RuntimeError(f"Cannot open cart webcam (device {cart_cam_id})")

        # ÏõπÏ∫† Ìï¥ÏÉÅÎèÑ ÏÑ§Ï†ï
        self.cart_cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cart_cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

        # Product recognizer for debug visualization
        print("ÏÉÅÌíà Ïù∏Ïãù Î™®Îç∏ Î°úÎî© Ï§ë...")
        self.product_recognizer = ProductRecognizer()
        print("Î™®Îç∏ Î°úÎî© ÏôÑÎ£å!")

        # Obstacle detector for front camera visualization
        print("Ïû•Ïï†Î¨º Í∞êÏßÄ Î™®Îç∏ Î°úÎî© Ï§ë...")
        self.obstacle_detector = ObstacleDetector()
        print("Ïû•Ïï†Î¨º Í∞êÏßÄ Î™®Îç∏ Î°úÎî© ÏôÑÎ£å!")

        # Frame queues for display
        self.front_frame_queue = Queue(maxsize=2)
        self.cart_frame_queue = Queue(maxsize=2)

        # Last obstacle detection result
        self.last_obstacle_result = None
        self.obstacle_lock = threading.Lock()

        self.is_running = True

        print("=" * 60)
        print("ÏµúÏ†ÅÌôîÎêú ÌïòÏù¥Î∏åÎ¶¨Îìú Ïπ¥Î©îÎùº Ïï± (ÎîîÎ≤ÑÍ∑∏ Î∞ïÏä§)")
        print(f"  Ï†ÑÎ∞©: ÏõπÏ∫† {front_cam_id} (Ïû•Ïï†Î¨º Í∞êÏßÄ)")
        print(f"  Ïπ¥Ìä∏: ÏõπÏ∫† {cart_cam_id} (ÏÉÅÌíà Ïù∏Ïãù Î∞îÏö¥Îî© Î∞ïÏä§ ÌëúÏãú)")
        print(f"  Main Hub: {main_hub_ip}")
        print("=" * 60)

    def _capture_video_thread(self):
        """Ï†ÑÎ∞© ÏõπÏ∫† Ï∫°Ï≤ò Ïä§Î†àÎìú (Ïû•Ïï†Î¨º Í∞êÏßÄ Ìè¨Ìï®)"""
        print(f"[Ï†ÑÎ∞©] ÏõπÏ∫† {self.front_cam_id} Ï∫°Ï≤ò ÏãúÏûë")
        frame_count = 0

        while self.is_running:
            ret, frame = self.front_cap.read()

            if not ret:
                time.sleep(0.1)
                continue

            frame_count += 1

            # Î¶¨ÏÇ¨Ïù¥Ï¶à
            resized = ImageProcessor.resize_for_ai(
                frame, (self.img_width, self.img_height)
            )

            # UDP Ï†ÑÏÜ°
            self.front_sender.send_frame(resized)

            # Ïû•Ïï†Î¨º Í∞êÏßÄ (2ÌîÑÎ†àÏûÑÎßàÎã§)
            if frame_count % 2 == 0:
                try:
                    result = self.obstacle_detector.detect(resized)
                    with self.obstacle_lock:
                        self.last_obstacle_result = result
                except Exception as e:
                    print(f"[Ï†ÑÎ∞©] Ïû•Ïï†Î¨º Í∞êÏßÄ Ïò§Î•ò: {e}")

            # ÎîîÏä§ÌîåÎ†àÏù¥Ïö© ÌîÑÎ†àÏûÑ ÏÉùÏÑ± (ÏãúÍ∞ÅÌôî Ìè¨Ìï®)
            display_frame = resized.copy()

            with self.obstacle_lock:
                if self.last_obstacle_result:
                    display_frame = self._draw_obstacle_info(
                        display_frame, self.last_obstacle_result
                    )

            # ÎîîÏä§ÌîåÎ†àÏù¥ ÌÅêÏóê Ï∂îÍ∞Ä
            if not self.front_frame_queue.full():
                self.front_frame_queue.put(display_frame)

            time.sleep(self.video_interval)

        print("[Ï†ÑÎ∞©] Ï∫°Ï≤ò Ï¢ÖÎ£å")

    def _draw_obstacle_info(self, frame, result):
        """Ïû•Ïï†Î¨º Í∞êÏßÄ Í≤∞Í≥ºÎ•º ÌîÑÎ†àÏûÑÏóê ÌëúÏãú"""
        h, w = frame.shape[:2]

        # ÏúÑÌóò Î†àÎ≤® Ï†ïÎ≥¥
        level = result.get("level", 0)
        risk_names = ["SAFE", "CAUTION", "WARN"]
        risk_colors = [(0, 255, 0), (0, 255, 255), (0, 0, 255)]  # Green, Yellow, Red

        risk_name = risk_names[level]
        risk_color = risk_colors[level]

        # Î∞∞Í≤Ω Ïò§Î≤ÑÎ†àÏù¥ (ÏÉÅÎã®)
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (w, 100), (0, 0, 0), -1)
        frame = cv2.addWeighted(frame, 0.6, overlay, 0.4, 0)

        # ÏúÑÌóò Î†àÎ≤® ÌÅ¨Í≤å ÌëúÏãú
        cv2.putText(
            frame,
            f"Risk: {risk_name}",
            (10, 40),
            cv2.FONT_HERSHEY_SIMPLEX,
            1.2,
            risk_color,
            3,
        )

        # Í∞ùÏ≤¥ Í∞úÏàò
        obj_count = len(result.get("objects", []))
        cv2.putText(
            frame,
            f"Objects: {obj_count}",
            (10, 75),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.7,
            (255, 255, 255),
            2,
        )

        # Î™®Îì† Í∞êÏßÄÎêú Í∞ùÏ≤¥ Î∞ïÏä§ Í∑∏Î¶¨Í∏∞
        for obj in result.get("objects", []):
            box = obj.get("box", [0, 0, 0, 0])
            x1, y1, x2, y2 = box
            track_id = obj.get("track_id", -1)
            risk_level = obj.get("risk_level", 0)
            class_name = obj.get("class_name", "unknown")
            confidence = obj.get("confidence", 0.0)

            # ÏúÑÌóòÎèÑÏóê Îî∞Î•∏ ÏÉâÏÉÅ
            box_color = risk_colors[risk_level]
            thickness = 3 if risk_level >= 1 else 2

            # Î∞ïÏä§ Í∑∏Î¶¨Í∏∞
            cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, thickness)

            # ÎùºÎ≤® Î∞∞Í≤Ω
            label = f"{class_name} #{track_id}"
            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
            cv2.rectangle(
                frame,
                (x1, y1 - label_size[1] - 10),
                (x1 + label_size[0] + 10, y1),
                box_color,
                -1,
            )

            # ÎùºÎ≤® ÌÖçÏä§Ìä∏
            cv2.putText(
                frame,
                label,
                (x1 + 5, y1 - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 255, 255),
                2,
            )

            # Ï∂îÍ∞Ä Ï†ïÎ≥¥ (Î∞ïÏä§ ÌïòÎã®)
            info_lines = []
            if obj.get("in_center"):
                info_lines.append("CENTER")
            if obj.get("approaching"):
                info_lines.append("APPROACHING")

            pttc = obj.get("pttc_s", 1e9)
            if pttc < 1e6:
                info_lines.append(f"TTC:{pttc:.1f}s")

            if info_lines:
                info_text = " | ".join(info_lines)
                cv2.putText(
                    frame,
                    info_text,
                    (x1, y2 + 20),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.5,
                    box_color,
                    2,
                )

        # ÏµúÍ≥† ÏúÑÌóò Í∞ùÏ≤¥ Ï†ïÎ≥¥ (ÌïòÎã®)
        highest_risk = result.get("highest_risk_object")
        if highest_risk:
            track_id = highest_risk.get("track_id", -1)
            pttc = highest_risk.get("pttc_s", 1e9)
            risk_score = highest_risk.get("score", 0.0)

            # ÌïòÎã® Ï†ïÎ≥¥ Î∞∞Í≤Ω
            overlay = frame.copy()
            cv2.rectangle(overlay, (0, h - 60), (w, h), (0, 0, 0), -1)
            frame = cv2.addWeighted(frame, 0.6, overlay, 0.4, 0)

            info_text = f"Highest Risk: Track #{track_id}"
            cv2.putText(
                frame,
                info_text,
                (10, h - 35),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (255, 255, 255),
                2,
            )

            if pttc < 1e6:
                pttc_text = f"pTTC: {pttc:.1f}s | Score: {risk_score:.1f}"
            else:
                pttc_text = f"Score: {risk_score:.1f}"

            cv2.putText(
                frame,
                pttc_text,
                (10, h - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (255, 255, 255),
                2,
            )

        return frame

    def _capture_webcam_thread(self):
        """ÏõπÏ∫† Ï∫°Ï≤ò Ïä§Î†àÎìú (ÏÉÅÌíà Ïù∏Ïãù Ìè¨Ìï® - Î™®ÏÖò Ìä∏Î¶¨Í±∞)"""
        print("[Ïπ¥Ìä∏] ÏõπÏ∫† Ï∫°Ï≤ò ÏãúÏûë (ROI + Î™®ÏÖò Ìä∏Î¶¨Í±∞ ÌôúÏÑ±Ìôî)")
        interval = 1.0 / self.fps
        frame_count = 0
        last_result = None

        while self.is_running:
            ret, frame = self.cart_cap.read()
            if not ret:
                time.sleep(interval)
                continue

            frame_count += 1

            # Î¶¨ÏÇ¨Ïù¥Ï¶à
            resized = ImageProcessor.resize_for_ai(
                frame, (self.img_width, self.img_height)
            )

            # UDP Ï†ÑÏÜ°
            self.cart_sender.send_frame(resized)

            # ÎîîÏä§ÌîåÎ†àÏù¥Ïö© ÌîÑÎ†àÏûÑ
            display_frame = resized.copy()

            # ÏÉÅÌíà Ïù∏Ïãù (Î™®ÏÖò Ìä∏Î¶¨Í±∞ Î∞©Ïãù)
            if frame_count % 2 == 0:  # 2ÌîÑÎ†àÏûÑÎßàÎã§ Ïù∏Ïãù (Îçî Îπ†Î•∏ Î∞òÏùë)
                try:
                    current_time = time.time()
                    last_result = self.product_recognizer.recognize_with_trigger(
                        resized, current_time
                    )
                except Exception as e:
                    last_result = {"status": "error", "message": str(e)}

            # ÏãúÏä§ÌÖú ÏÉÅÌÉú ÌëúÏãú
            zones = self.product_recognizer.get_debug_zones(display_frame.shape)
            h, w = display_frame.shape[:2]

            # ÏÉÅÌÉú Ï†ïÎ≥¥ ÌëúÏãú (ÏÉÅÎã®)
            info_text = [
                f"Tracking: {zones['tracked_count']}",
                f"Cooldown: {zones['cooldown_count']}",
                f"Duration: {zones['required_duration']:.1f}s",
            ]
            y_offset = 30
            for text in info_text:
                cv2.putText(
                    display_frame,
                    text,
                    (10, y_offset),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    (0, 255, 0),
                    2,
                )
                y_offset += 30

            # Ïù∏Ïãù Í≤∞Í≥º ÏãúÍ∞ÅÌôî
            if last_result:
                status = last_result.get("status")
                main_event = last_result.get("main_event")
                all_detections = last_result.get("all_detections", [])

                # Î™®Îì† Í∞êÏßÄÎêú Î¨ºÏ≤¥Îì§Ïùò Î∞îÏö¥Îî© Î∞ïÏä§ ÌëúÏãú
                for detection in all_detections:
                    bbox = detection.get("bbox")
                    if not bbox:
                        continue

                    x1, y1, x2, y2 = map(int, bbox)
                    product_id = detection.get("product_id")
                    confidence = detection.get("confidence", 0.0)
                    state = detection.get("state", "unknown")

                    # ÏÉÅÌÉúÎ≥Ñ ÏÉâÏÉÅ Î∞è ÎùºÎ≤® ÏÑ§Ï†ï
                    if state == "added":
                        # üéâ Ïπ¥Ìä∏Ïóê Ï∂îÍ∞ÄÎê® (Ï£ºÌô©ÏÉâ)
                        color = (0, 165, 255)
                        thickness = 4
                        duration = detection.get("duration", 0.0)
                        label = f"ADDED! ID:{product_id} ({duration:.1f}s)"
                    elif state == "tracking":
                        # Ï∂îÏ†Å Ï§ë (ÎÖ∏ÎûÄÏÉâ)
                        color = (0, 255, 255)
                        thickness = 3
                        duration = detection.get("duration", 0.0)
                        remaining = detection.get("remaining", 0.0)
                        label = (
                            f"Tracking ID:{product_id} {duration:.1f}s/{remaining:.1f}s"
                        )
                    elif state == "cooldown":
                        # Ïø®Îã§Ïö¥ Ï§ë (ÌöåÏÉâ)
                        color = (128, 128, 128)
                        thickness = 2
                        cooldown_time = detection.get("cooldown_remaining", 0)
                        label = f"Cooldown ID:{product_id} ({cooldown_time:.1f}s)"
                    else:
                        # Í∏∞ÌÉÄ (Ï¥àÎ°ùÏÉâ)
                        color = (0, 255, 0)
                        thickness = 2
                        label = f"ID:{product_id} {confidence:.2f}"

                    # Î∞îÏö¥Îî© Î∞ïÏä§ Í∑∏Î¶¨Í∏∞
                    cv2.rectangle(display_frame, (x1, y1), (x2, y2), color, thickness)

                    # Î†àÏù¥Î∏î Î∞∞Í≤Ω
                    label_size, _ = cv2.getTextSize(
                        label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
                    )
                    cv2.rectangle(
                        display_frame,
                        (x1, y1 - label_size[1] - 10),
                        (x1 + label_size[0], y1),
                        color,
                        -1,
                    )

                    # Î†àÏù¥Î∏î ÌÖçÏä§Ìä∏
                    text_color = (255, 255, 255) if state == "added" else (0, 0, 0)
                    cv2.putText(
                        display_frame,
                        label,
                        (x1, y1 - 5),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.6,
                        text_color,
                        2,
                    )

                # ÌôîÎ©¥ ÏÉÅÎã® Î©îÏãúÏßÄ
                if status == "added" and main_event:
                    # Ï∂îÍ∞ÄÎê® ÏïåÎ¶º
                    cv2.putText(
                        display_frame,
                        "PRODUCT ADDED TO CART!",
                        (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.8,
                        (0, 165, 255),
                        2,
                    )
                elif status == "tracking" and main_event:
                    # Ï∂îÏ†Å Ï§ë Î©îÏãúÏßÄ
                    zone = main_event.get("zone", "")
                    cv2.putText(
                        display_frame,
                        f"Tracking... ({zone})",
                        (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.7,
                        (0, 255, 255),
                        2,
                    )
                elif status == "none":
                    # Ïù∏Ïãù ÏïàÎê®
                    if len(all_detections) == 0:
                        cv2.putText(
                            display_frame,
                            "Waiting for product...",
                            (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX,
                            0.7,
                            (128, 128, 128),
                            2,
                        )

                elif status == "error":
                    cv2.putText(
                        display_frame,
                        f"Error: {last_result.get('message', '')[:40]}",
                        (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.5,
                        (0, 0, 255),
                        2,
                    )
                else:
                    # Ïù∏Ïãù ÏïàÎê®
                    cv2.putText(
                        display_frame,
                        "Waiting for product...",
                        (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        0.7,
                        (128, 128, 128),
                        2,
                    )

            # Ï∂îÏ†Å Ï†ïÎ≥¥ ÌëúÏãú
            info_y = 60
            cv2.putText(
                display_frame,
                f"Tracked: {zones['tracked_count']} | Cooldown: {zones['cooldown_count']}",
                (10, info_y),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1,
            )

            # FPS ÌëúÏãú
            cv2.putText(
                display_frame,
                f"Frame: {frame_count}",
                (10, display_frame.shape[0] - 10),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.5,
                (255, 255, 255),
                1,
            )

            # ÎîîÏä§ÌîåÎ†àÏù¥ ÌÅêÏóê Ï∂îÍ∞Ä
            if not self.cart_frame_queue.full():
                self.cart_frame_queue.put(display_frame)

            time.sleep(interval)

        print("[Ïπ¥Ìä∏] Ï∫°Ï≤ò Ï¢ÖÎ£å")

    def run(self):
        """Î©îÏù∏ Ïã§Ìñâ"""
        # Ï∫°Ï≤ò Ïä§Î†àÎìú ÏãúÏûë
        front_thread = threading.Thread(target=self._capture_video_thread, daemon=True)
        cart_thread = threading.Thread(target=self._capture_webcam_thread, daemon=True)

        front_thread.start()
        cart_thread.start()

        print("\nÌôîÎ©¥ ÌëúÏãú ÏãúÏûë ('q' ÌÇ§Î°ú Ï¢ÖÎ£å)...")

        # Î©îÏù∏ Ïä§Î†àÎìúÏóêÏÑú ÌôîÎ©¥ ÌëúÏãú
        try:
            while self.is_running:
                # Ï†ÑÎ∞© Ïπ¥Î©îÎùº ÌîÑÎ†àÏûÑ ÌëúÏãú
                if not self.front_frame_queue.empty():
                    front_frame = self.front_frame_queue.get()
                    cv2.imshow("Front Camera (Obstacle)", front_frame)

                # Ïπ¥Ìä∏ Ïπ¥Î©îÎùº ÌîÑÎ†àÏûÑ ÌëúÏãú (Î∞îÏö¥Îî© Î∞ïÏä§ Ìè¨Ìï®)
                if not self.cart_frame_queue.empty():
                    cart_frame = self.cart_frame_queue.get()
                    cv2.imshow("Cart Camera (Product - Debug)", cart_frame)

                # ÌÇ§ ÏûÖÎ†• ÌôïÏù∏
                key = cv2.waitKey(1) & 0xFF
                if key == ord("q"):
                    print("\nÏ¢ÖÎ£å ÏöîÏ≤≠...")
                    self.is_running = False
                    break

        except KeyboardInterrupt:
            print("\n\nÏ¢ÖÎ£å ÏöîÏ≤≠...")
            self.is_running = False

        # Ïä§Î†àÎìú Ï¢ÖÎ£å ÎåÄÍ∏∞
        front_thread.join(timeout=2)
        cart_thread.join(timeout=2)

        # Î¶¨ÏÜåÏä§ Ï†ïÎ¶¨
        self.front_cap.release()
        self.cart_cap.release()
        cv2.destroyAllWindows()
        print("Ï¢ÖÎ£å ÏôÑÎ£å")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="ÏµúÏ†ÅÌôîÎêú ÌïòÏù¥Î∏åÎ¶¨Îìú Ïπ¥Î©îÎùº Ïï± (ÎìÄÏñº ÏõπÏ∫†)"
    )
    parser.add_argument(
        "--front",
        type=int,
        default=0,
        help="Ï†ÑÎ∞© Ïπ¥Î©îÎùº Ïû•Ïπò Î≤àÌò∏ (Í∏∞Î≥∏Í∞í: 0)",
    )
    parser.add_argument(
        "--cart",
        type=int,
        default=1,
        help="Ïπ¥Ìä∏ Ïπ¥Î©îÎùº Ïû•Ïπò Î≤àÌò∏ (Í∏∞Î≥∏Í∞í: 1)",
    )

    args = parser.parse_args()

    try:
        app = OptimizedHybridCameraApp(front_cam_id=args.front, cart_cam_id=args.cart)
        app.run()
    except Exception as e:
        print(f"ERROR: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)
