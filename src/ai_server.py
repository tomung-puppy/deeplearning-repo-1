# ai_server.py
# ai_server.py
import threading
import time
import cv2
import numpy as np

from network.udp_handler import UDPFrameReceiver
from network.tcp_client import TCPClient
from common.config import config
from common.protocols import (
    Protocol,
    AIEvent,
    DangerLevel,
)
from detectors.obstacle_dl import ObstacleDetector
from detectors.product_dl import ProductRecognizer


class AIServer:
    """
    AI Server (PC1)

    - Receives frames via UDP from Main PC2.
    - Performs inference on frames.
    - Pushes events (e.g., product detected, obstacle detected) to Main PC2.
    """

    def __init__(self):
        print("Initializing AI Server...")
        if config is None:
            raise RuntimeError("Configuration could not be loaded. Exiting.")

        # -------------------------
        # Models
        # -------------------------
        self.obstacle_model = ObstacleDetector()
        self.product_model = ProductRecognizer()

        # -------------------------
        # Latest frame buffers & Locks
        # -------------------------
        self._latest_obstacle_bytes = None
        self._obstacle_lock = threading.Lock()

        self._latest_product_bytes = None
        self._product_lock = threading.Lock()

        # -------------------------
        # UDP receivers for frame data
        # -------------------------
        self.obstacle_receiver = UDPFrameReceiver("0.0.0.0", config.network.pc1_ai.udp_front_port)
        self.product_receiver = UDPFrameReceiver("0.0.0.0", config.network.pc1_ai.udp_cart_port)
        print(f"UDP receivers listening on ports {config.network.pc1_ai.udp_front_port} and {config.network.pc1_ai.udp_cart_port}")

        # -------------------------
        # TCP client to push events to Main Hub
        # -------------------------
        main_hub_ip = config.network.pc2_main.ip
        main_hub_port = config.network.pc2_main.event_port
        self.event_client = TCPClient(main_hub_ip, main_hub_port)
        print(f"Event client configured to connect to {main_hub_ip}:{main_hub_port}")

    # =========================
    # UDP receive loops
    # =========================
    def _obstacle_udp_loop(self):
        print("Obstacle UDP loop started.")
        for jpeg_bytes in self.obstacle_receiver.receive_packets():
            with self._obstacle_lock:
                self._latest_obstacle_bytes = jpeg_bytes

    def _product_udp_loop(self):
        print("Product UDP loop started.")
        for jpeg_bytes in self.product_receiver.receive_packets():
            with self._product_lock:
                self._latest_product_bytes = jpeg_bytes

    # =========================
    # Inference loops
    # =========================
    def _obstacle_inference_loop(self):
        print("Obstacle inference loop started.")
        while True:
            with self._obstacle_lock:
                jpeg = self._latest_obstacle_bytes
            
            if jpeg is None:
                time.sleep(0.1)
                continue

            frame = self._decode(jpeg)
            if frame is None:
                continue

            result = self.obstacle_model.detect(frame)
            level = DangerLevel(result.get("level", 0))

            # Push event if danger is detected. Debouncing is handled by the main hub's engine.
            if level >= DangerLevel.CAUTION:
                self._push_event(AIEvent.OBSTACLE_DANGER, result)
            
            time.sleep(0.05) # Control inference frequency

    def _product_inference_loop(self):
        print("Product inference loop started.")
        while True:
            with self._product_lock:
                jpeg = self._latest_product_bytes
            
            if jpeg is None:
                time.sleep(0.1)
                continue

            frame = self._decode(jpeg)
            if frame is None:
                continue

            result = self.product_model.recognize(frame)
            product_id = result.get("product_id")

            # Push event for every successful recognition. Debouncing is handled by the main hub's engine.
            if product_id:
                self._push_event(AIEvent.PRODUCT_DETECTED, {"product_id": product_id})
            
            time.sleep(0.1) # Control inference frequency

    # =========================
    # Utilities
    # =========================
    @staticmethod
    def _decode(jpeg_bytes: bytes):
        try:
            arr = np.frombuffer(jpeg_bytes, np.uint8)
            return cv2.imdecode(arr, cv2.IMREAD_COLOR)
        except Exception as e:
            print(f"Error decoding frame: {e}")
            return None

    # =========================
    # PUSH (AI â†’ Main PC2)
    # =========================
    def _push_event(self, event: AIEvent, data: dict):
        try:
            msg = Protocol.ai_event(event, data)
            self.event_client.send_request(msg)
        except Exception as e:
            print(f"Failed to push AI event: {e}")

    # =========================
    # Lifecycle
    # =========================
    def run(self):
        print("Starting AI Server threads...")
        threads = [
            threading.Thread(target=self._obstacle_udp_loop, daemon=True),
            threading.Thread(target=self._product_udp_loop, daemon=True),
            threading.Thread(target=self._obstacle_inference_loop, daemon=True),
            threading.Thread(target=self._product_inference_loop, daemon=True),
        ]

        for t in threads:
            t.start()
        
        print("AI Server is running.")
        # Keep main thread alive
        for t in threads:
            t.join()


if __name__ == "__main__":
    AIServer().run()
