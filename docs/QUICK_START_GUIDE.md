# í”„ë¡œê·¸ë¨ ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

## ğŸ“Œ ëª©ì°¨
1. [ì „ì²´ ì‹œìŠ¤í…œ ì‹¤í–‰ ë°©ë²• (3ëŒ€ PC)](#1-ì „ì²´-ì‹œìŠ¤í…œ-ì‹¤í–‰-ë°©ë²•-3ëŒ€-pc)
2. [PC 1ëŒ€ë¡œ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë°©ë²•](#2-pc-1ëŒ€ë¡œ-í…ŒìŠ¤íŠ¸í•˜ëŠ”-ë°©ë²•)
3. [ìƒí’ˆ ì¸ì‹ ê¸°ëŠ¥ êµ¬í˜„ ìœ„ì¹˜](#3-ìƒí’ˆ-ì¸ì‹-ê¸°ëŠ¥-êµ¬í˜„-ìœ„ì¹˜)

---

## 1. ì „ì²´ ì‹œìŠ¤í…œ ì‹¤í–‰ ë°©ë²• (3ëŒ€ PC)

### 1.1 ì‚¬ì „ ì¤€ë¹„

#### ëª¨ë“  PCì—ì„œ ê³µí†µ ì‘ì—…
```bash
# 1. í”„ë¡œì íŠ¸ í´ë¡ 
cd /home/dh/dev_ws/git_ws
git clone <repository-url> deeplearning-repo-1
cd deeplearning-repo-1

# 2. Python ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows

# 3. íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# 4. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (.env íŒŒì¼ ìƒì„±)
cp .env.example .env
# .env íŒŒì¼ì„ í¸ì§‘í•˜ì—¬ DB ì •ë³´ ì…ë ¥
```

#### DB ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ì‹¤í–‰)
```bash
# AWS RDSì— ì—°ê²°í•˜ì—¬ ìŠ¤í‚¤ë§ˆ ìƒì„±
mysql -h <RDS_ENDPOINT> -u <USERNAME> -p < scripts/init_db.sql

# ì´ˆê¸° ë°ì´í„° ì‚½ì…
python scripts/seed_data.py
```

#### YOLO ëª¨ë¸ ì¤€ë¹„
```bash
# models ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p models/obstacle_detector
mkdir -p models/product_recognizer

# YOLO ëª¨ë¸ íŒŒì¼ ë°°ì¹˜
# - models/obstacle_detector/best.pt  (ì¥ì• ë¬¼ ê°ì§€ìš©)
# - models/product_recognizer/best.pt (ìƒí’ˆ ì¸ì‹ìš©)
```

### 1.2 ì„¤ì • íŒŒì¼ ìˆ˜ì •

#### `configs/network_config.yaml`
```yaml
pc1_ai:
  ip: "192.168.1.101"        # AI ì„œë²„ IP (ì‹¤ì œ PC1 IPë¡œ ë³€ê²½)
  udp_front_port: 6001
  udp_cart_port: 6002

pc2_main:
  ip: "192.168.1.102"        # ë©”ì¸ í—ˆë¸Œ IP (ì‹¤ì œ PC2 IPë¡œ ë³€ê²½)
  event_port: 5001           # AI ì´ë²¤íŠ¸ ìˆ˜ì‹  í¬íŠ¸
  ui_request_port: 5002      # UI ìš”ì²­ ìˆ˜ì‹  í¬íŠ¸
  udp_front_cam_port: 6011   # ì „ë°© ì¹´ë©”ë¼ ìˆ˜ì‹  í¬íŠ¸
  udp_cart_cam_port: 6012    # ì¹´íŠ¸ ì¹´ë©”ë¼ ìˆ˜ì‹  í¬íŠ¸

pc3_ui:
  ip: "192.168.1.103"        # UI ì•± IP (ì‹¤ì œ PC3 IPë¡œ ë³€ê²½)
  command_port: 5003         # UI ëª…ë ¹ ìˆ˜ì‹  í¬íŠ¸
```

### 1.3 ì‹¤í–‰ ìˆœì„œ

#### **PC1 (AI Server)** - AI ì¶”ë¡  ì „ë‹´
```bash
cd /home/dh/dev_ws/git_ws/deeplearning-repo-1
source venv/bin/activate
python src/ai_server.py
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
Initializing AI Server...
Loading obstacle detection model...
Loading product recognition model...
UDP receivers listening on ports 6001 and 6002
Event client configured to connect to 192.168.1.102:5001
Obstacle UDP loop started.
Product UDP loop started.
Obstacle inference loop started.
Product inference loop started.
```

---

#### **PC2 (Main Hub)** - ì¤‘ì•™ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
```bash
cd /home/dh/dev_ws/git_ws/deeplearning-repo-1
source venv/bin/activate
python src/main_hub.py
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
Initializing Main Hub...
Database connection established
Starting shopping session...
Session ID: 1
TCP servers started (event_port=5001, ui_request_port=5002)
UDP forwarding to AI server started
System ready!
```

---

#### **PC3 (Edge Device)** - ì¹´ë©”ë¼ & UI

**Terminal 1: ì¹´ë©”ë¼ ì•±**
```bash
cd /home/dh/dev_ws/git_ws/deeplearning-repo-1
source venv/bin/activate
python src/cart_camera_app.py
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
Front camera streaming started
Cart camera streaming started
Streaming frames at 30 FPS...
```

**Terminal 2: UI ëŒ€ì‹œë³´ë“œ**
```bash
cd /home/dh/dev_ws/git_ws/deeplearning-repo-1
source venv/bin/activate
python src/cart_ui_app.py
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
UI Application started. Connecting to Main Hub at 192.168.1.102
Dashboard window opened
```

---

### 1.4 ë™ì‘ í™•ì¸

1. **UI ëŒ€ì‹œë³´ë“œ**ê°€ í™”ë©´ì— í‘œì‹œë¨
2. **ì¹´íŠ¸ ë‚´ë¶€ ì¹´ë©”ë¼**ì— ìƒí’ˆì„ ë„£ìœ¼ë©´:
   - AI Serverì—ì„œ ìƒí’ˆ ì¸ì‹
   - Main Hubì—ì„œ DB ì¡°íšŒ
   - UIì— ì¥ë°”êµ¬ë‹ˆ ì•„ì´í…œ ì¶”ê°€
3. **ì „ë°© ì¹´ë©”ë¼**ì— ì‚¬ëŒì´ ì§€ë‚˜ê°€ë©´:
   - AI Serverì—ì„œ ì¥ì• ë¬¼ ê°ì§€
   - Main Hubì—ì„œ ìœ„í—˜ë„ íŒë‹¨
   - UIì— ê²½ê³  í‘œì‹œ
4. **ì²´í¬ì•„ì›ƒ ë²„íŠ¼** í´ë¦­:
   - DBì— ì£¼ë¬¸ ì €ì¥
   - UI ì´ˆê¸°í™”

---

## 2. PC 1ëŒ€ë¡œ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë°©ë²•

PCê°€ 1ëŒ€ë°–ì— ì—†ëŠ” ê²½ìš°, ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ë™ì¼í•œ PCì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 2.1 ì„¤ì • ë³€ê²½

#### `configs/network_config.yaml`
```yaml
# ëª¨ë“  IPë¥¼ localhostë¡œ ì„¤ì •
pc1_ai:
  ip: "127.0.0.1"
  udp_front_port: 6001
  udp_cart_port: 6002

pc2_main:
  ip: "127.0.0.1"
  event_port: 5001
  ui_request_port: 5002
  udp_front_cam_port: 6011
  udp_cart_cam_port: 6012

pc3_ui:
  ip: "127.0.0.1"
  command_port: 5003
```

### 2.2 ì‹¤í–‰ ìˆœì„œ (í„°ë¯¸ë„ 4ê°œ ì‚¬ìš©)

#### Terminal 1: AI Server
```bash
cd /home/dh/dev_ws/git_ws/deeplearning-repo-1
source venv/bin/activate
python src/ai_server.py
```

#### Terminal 2: Main Hub
```bash
cd /home/dh/dev_ws/git_ws/deeplearning-repo-1
source venv/bin/activate
python src/main_hub.py
```

#### Terminal 3: ì¹´ë©”ë¼ ì•± (ì›¹ìº  ì‚¬ìš©)
```bash
cd /home/dh/dev_ws/git_ws/deeplearning-repo-1
source venv/bin/activate
python src/cart_camera_app.py
```

**ì¤‘ìš”**: `cart_camera_app.py`ê°€ ì¹´ë©”ë¼ 2ëŒ€ë¥¼ ì°¾ì§€ ëª»í•˜ë©´ ì—ëŸ¬ ë°œìƒ
- í•´ê²° ë°©ë²•: ì•„ë˜ "2.3 ì¹´ë©”ë¼ ì—†ì´ í…ŒìŠ¤íŠ¸" ì°¸ì¡°

#### Terminal 4: UI ì•±
```bash
cd /home/dh/dev_ws/git_ws/deeplearning-repo-1
source venv/bin/activate
python src/cart_ui_app.py
```

### 2.3 ì¹´ë©”ë¼ ì—†ì´ í…ŒìŠ¤íŠ¸ (ë…¹í™” ì˜ìƒ ì‚¬ìš©)

ì‹¤ì œ ì¹´ë©”ë¼ê°€ ì—†ëŠ” ê²½ìš°, ë…¹í™”ëœ ì˜ìƒ íŒŒì¼ë¡œ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•©ë‹ˆë‹¤.

#### í…ŒìŠ¤íŠ¸ìš© ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë¨¸ ìƒì„±
```bash
# test/video_streamer.py íŒŒì¼ ìƒì„±
cat > test/video_streamer.py << 'EOF'
#!/usr/bin/env python3
"""
ë…¹í™”ëœ ì˜ìƒ íŒŒì¼ì„ ì½ì–´ì„œ UDPë¡œ ì „ì†¡í•˜ëŠ” í…ŒìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë¨¸
"""
import cv2
import time
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

from network.udp_handler import UDPFrameSender

def stream_video_file(video_path, host, port, fps=30):
    """ì˜ìƒ íŒŒì¼ì„ UDPë¡œ ìŠ¤íŠ¸ë¦¬ë°"""
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Error: Cannot open video file: {video_path}")
        return
    
    sender = UDPFrameSender(host, port, jpeg_quality=80)
    interval = 1.0 / fps
    
    print(f"Streaming {video_path} to {host}:{port} at {fps} FPS")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            # ì˜ìƒ ëë‚˜ë©´ ì²˜ìŒë¶€í„° ë‹¤ì‹œ
            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            continue
        
        sender.send_frame(frame)
        time.sleep(interval)

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("video", help="Path to video file")
    parser.add_argument("--host", default="127.0.0.1")
    parser.add_argument("--port", type=int, default=6011)
    parser.add_argument("--fps", type=int, default=30)
    
    args = parser.parse_args()
    
    try:
        stream_video_file(args.video, args.host, args.port, args.fps)
    except KeyboardInterrupt:
        print("\nStreaming stopped")
EOF

chmod +x test/video_streamer.py
```

#### í…ŒìŠ¤íŠ¸ ì˜ìƒ ì¤€ë¹„
```bash
# í…ŒìŠ¤íŠ¸ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ë˜ëŠ” ìì²´ ì œì‘
# test/yw/data/raw/ ë””ë ‰í† ë¦¬ì— ë°°ì¹˜
# - front_camera_test.mp4  (ì „ë°© ì¹´ë©”ë¼ìš©)
# - cart_camera_test.mp4   (ì¹´íŠ¸ ì¹´ë©”ë¼ìš©)
```

#### ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë¨¸ ì‹¤í–‰
```bash
# Terminal 3-1: ì „ë°© ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼
python test/video_streamer.py test/yw/data/raw/front_camera_test.mp4 \
    --host 127.0.0.1 --port 6011 --fps 30

# Terminal 3-2: ì¹´íŠ¸ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼
python test/video_streamer.py test/yw/data/raw/cart_camera_test.mp4 \
    --host 127.0.0.1 --port 6012 --fps 30
```

### 2.4 ê°„ë‹¨í•œ í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

```bash
# test/quick_test.sh íŒŒì¼ ìƒì„±
cat > test/quick_test.sh << 'EOF'
#!/bin/bash
# ëª¨ë“  ì»´í¬ë„ŒíŠ¸ë¥¼ ë°±ê·¸ë¼ìš´ë“œë¡œ ì‹¤í–‰í•˜ëŠ” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

PROJECT_ROOT="$(cd "$(dirname "$0")/.." && pwd)"
cd "$PROJECT_ROOT"

# ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p logs

# 1. AI Server ì‹œì‘
echo "Starting AI Server..."
python src/ai_server.py > logs/ai_server.log 2>&1 &
AI_PID=$!
sleep 3

# 2. Main Hub ì‹œì‘
echo "Starting Main Hub..."
python src/main_hub.py > logs/main_hub.log 2>&1 &
MAIN_PID=$!
sleep 3

# 3. ì¹´ë©”ë¼ ì•± ì‹œì‘ (ì›¹ìº  ì‚¬ìš©)
echo "Starting Camera App..."
python src/cart_camera_app.py > logs/camera_app.log 2>&1 &
CAM_PID=$!
sleep 2

# 4. UI ì•± ì‹œì‘ (í¬ê·¸ë¼ìš´ë“œ)
echo "Starting UI App..."
python src/cart_ui_app.py

# UI ì¢…ë£Œ ì‹œ ëª¨ë“  í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
echo "Shutting down..."
kill $AI_PID $MAIN_PID $CAM_PID 2>/dev/null
echo "All processes stopped"
EOF

chmod +x test/quick_test.sh
```

**ì‹¤í–‰:**
```bash
./test/quick_test.sh
```

---

## 3. ìƒí’ˆ ì¸ì‹ ê¸°ëŠ¥ êµ¬í˜„ ìœ„ì¹˜

ìƒí’ˆ ì¸ì‹ ê¸°ëŠ¥ì€ ì—¬ëŸ¬ íŒŒì¼ì— ê±¸ì³ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê° ë‹¨ê³„ë³„ë¡œ ì–´ë””ë¥¼ ìˆ˜ì •í•´ì•¼ í•˜ëŠ”ì§€ ì„¤ëª…í•©ë‹ˆë‹¤.

### 3.1 í•µì‹¬ êµ¬í˜„ ìœ„ì¹˜

#### ğŸ“ `src/detectors/product_dl.py` - **ê°€ì¥ ì¤‘ìš”**
**ì—­í• **: YOLO ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¹´ë©”ë¼ í”„ë ˆì„ì—ì„œ ìƒí’ˆì„ ì¸ì‹

**í˜„ì¬ êµ¬í˜„:**
```python
from ultralytics import YOLO

class ProductRecognizer:
    def __init__(self, model_path='models/product_recognizer/best.pt'):
        self.model = YOLO(model_path)
        self.threshold = 0.7  # ìƒí’ˆ ì¸ì‹ ì‹ ë¢°ë„ ì„ê³„ê°’

    def recognize(self, frame):
        """
        í”„ë ˆì„ ë‚´ì˜ ìƒí’ˆì„ ì¸ì‹í•˜ì—¬ product_id ë°˜í™˜
        """
        results = self.model.predict(frame, conf=self.threshold, verbose=False)
        
        if len(results) > 0 and len(results[0].boxes) > 0:
            # ê°€ì¥ ì‹ ë¢°ë„ê°€ ë†’ì€ ì²« ë²ˆì§¸ ê°ì²´ ì„ íƒ
            top_box = results[0].boxes[0]
            product_id = int(top_box.cls[0])
            confidence = float(top_box.conf[0])
            
            return {
                "product_id": product_id,
                "confidence": confidence,
                "status": "detected"
            }
        
        return {"status": "none"}
```

**ìˆ˜ì • ë°©ë²• (ë” ë§ì€ ì •ë³´ ì¶”ì¶œ):**
```python
def recognize(self, frame):
    """
    í”„ë ˆì„ ë‚´ì˜ ëª¨ë“  ìƒí’ˆì„ ì¸ì‹í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    results = self.model.predict(frame, conf=self.threshold, verbose=False)
    
    detected_products = []
    
    if len(results) > 0:
        for box in results[0].boxes:
            product_id = int(box.cls[0])
            confidence = float(box.conf[0])
            bbox = box.xyxy[0].tolist()  # [x1, y1, x2, y2]
            
            detected_products.append({
                "product_id": product_id,
                "confidence": confidence,
                "bbox": bbox,  # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
                "status": "detected"
            })
    
    return detected_products if detected_products else [{"status": "none"}]
```

**ë°”ì½”ë“œ ì¸ì‹ ì¶”ê°€ (OCR ì‚¬ìš©):**
```python
import cv2
from pyzbar.pyzbar import decode  # pip install pyzbar

class ProductRecognizer:
    def __init__(self, model_path='models/product_recognizer/best.pt'):
        self.model = YOLO(model_path)
        self.threshold = 0.7

    def recognize(self, frame):
        """YOLO + ë°”ì½”ë“œ ìŠ¤ìº”"""
        # 1. YOLOë¡œ ìƒí’ˆ ì˜ì—­ ê²€ì¶œ
        results = self.model.predict(frame, conf=self.threshold, verbose=False)
        
        detected_products = []
        
        if len(results) > 0:
            for box in results[0].boxes:
                # ìƒí’ˆ ì˜ì—­ í¬ë¡­
                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
                cropped = frame[y1:y2, x1:x2]
                
                # 2. í¬ë¡­ëœ ì˜ì—­ì—ì„œ ë°”ì½”ë“œ ìŠ¤ìº”
                barcodes = decode(cropped)
                
                if barcodes:
                    barcode_data = barcodes[0].data.decode('utf-8')
                    detected_products.append({
                        "barcode": barcode_data,
                        "confidence": float(box.conf[0]),
                        "bbox": [x1, y1, x2, y2],
                        "status": "detected"
                    })
                else:
                    # ë°”ì½”ë“œ ì—†ìœ¼ë©´ í´ë˜ìŠ¤ ID ì‚¬ìš©
                    detected_products.append({
                        "product_id": int(box.cls[0]),
                        "confidence": float(box.conf[0]),
                        "bbox": [x1, y1, x2, y2],
                        "status": "detected"
                    })
        
        return detected_products if detected_products else [{"status": "none"}]
```

---

#### ğŸ“ `src/ai_server.py` - AI ì¶”ë¡  ë£¨í”„
**ì—­í• **: ì¹´ë©”ë¼ í”„ë ˆì„ì„ ë°›ì•„ì„œ `ProductRecognizer`ë¥¼ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ ë©”ì¸ í—ˆë¸Œë¡œ ì „ì†¡

**í˜„ì¬ êµ¬í˜„ (107-135ì¤„):**
```python
def _product_inference_loop(self):
    print("Product inference loop started.")
    while True:
        with self._product_lock:
            jpeg = self._latest_product_bytes
        
        if jpeg is None:
            time.sleep(0.1)
            continue

        frame = self._decode(jpeg)
        if frame is None:
            continue

        result = self.product_model.recognize(frame)
        
        # If a product is detected
        if result.get("status") == "detected":
            product_id = result.get("product_id")
            confidence = result.get("confidence", 0.0)
            
            msg = Protocol.make_event(
                event_type=AIEvent.PRODUCT_DETECTED,
                data={
                    "product_id": product_id,
                    "confidence": confidence,
                }
            )
            self._push_event(msg)
        
        time.sleep(0.1)
```

**ìˆ˜ì • ì˜ˆì‹œ (ë‹¤ì¤‘ ìƒí’ˆ ì²˜ë¦¬):**
```python
def _product_inference_loop(self):
    print("Product inference loop started.")
    while True:
        with self._product_lock:
            jpeg = self._latest_product_bytes
        
        if jpeg is None:
            time.sleep(0.1)
            continue

        frame = self._decode(jpeg)
        if frame is None:
            continue

        # recognize()ê°€ ì´ì œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
        results = self.product_model.recognize(frame)
        
        # ê°ì§€ëœ ëª¨ë“  ìƒí’ˆì— ëŒ€í•´ ì´ë²¤íŠ¸ ì „ì†¡
        for result in results:
            if result.get("status") == "detected":
                # barcode ë˜ëŠ” product_id ì‚¬ìš©
                identifier = result.get("barcode") or result.get("product_id")
                confidence = resultmodels/product_recognizer/product_yolo8s.pt.get("confidence", 0.0)
                
                msg = Protocol.make_event(
                    event_type=AIEvent.PRODUCT_DETECTED,
                    data={
                        "identifier": identifier,  # barcode ë˜ëŠ” product_id
                        "confidence": confidence,
                        "bbox": result.get("bbox"),  # ì‹œê°í™”ìš©
                    }
                )
                self._push_event(msg)
        
        time.sleep(0.1)
```

---

#### ğŸ“ `src/core/engine.py` - ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
**ì—­í• **: AIì—ì„œ ë°›ì€ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  DBì— ì €ì¥, UI ì—…ë°ì´íŠ¸

**í˜„ì¬ êµ¬í˜„ (ì¶”ì • ìœ„ì¹˜):**
```python
def process_product_event(self, event_data):
    """
    ìƒí’ˆ ê°ì§€ ì´ë²¤íŠ¸ ì²˜ë¦¬
    - Debouncing (ì¤‘ë³µ ë°©ì§€)
    - DBì—ì„œ ìƒí’ˆ ì •ë³´ ì¡°íšŒ
    - ì¥ë°”êµ¬ë‹ˆì— ì¶”ê°€
    - UIì— ëª…ë ¹ ì „ì†¡
    """
    product_id = event_data.get("product_id")
    
    # Debouncing: ê°™ì€ ìƒí’ˆì´ 5ì´ˆ ì´ë‚´ì— ì¬ê°ì§€ë˜ë©´ ë¬´ì‹œ
    current_time = time.time()
    if product_id in self._last_product_time:
        if current_time - self._last_product_time[product_id] < 5.0:
            return  # ì¤‘ë³µ ê°ì§€, ë¬´ì‹œ
    
    self._last_product_time[product_id] = current_time
    
    # DBì—ì„œ ìƒí’ˆ ì •ë³´ ì¡°íšŒ
    product = self.product_dao.get_product_by_id(product_id)
    if not product:
        print(f"Unknown product_id: {product_id}")
        return
    
    # ì¥ë°”êµ¬ë‹ˆì— ì¶”ê°€
    self.tx_dao.add_cart_item(
        session_id=self.current_session_id,
        product_id=product_id,
        quantity=1
    )
    
    # UI ì—…ë°ì´íŠ¸ ëª…ë ¹ ì „ì†¡
    cart_items = self.tx_dao.get_cart_items(self.current_session_id)
    total = sum(item['price'] * item['quantity'] for item in cart_items)
    
    ui_msg = Protocol.make_command(
        command_type=UICommand.UPDATE_CART,
        data={
            "items": cart_items,
            "total": total
        }
    )
    self.ui_client.send(ui_msg)
```

**ë°”ì½”ë“œ ê¸°ë°˜ ì²˜ë¦¬ë¡œ ìˆ˜ì •:**
```python
def process_product_event(self, event_data):
    """ë°”ì½”ë“œ ê¸°ë°˜ ìƒí’ˆ ì²˜ë¦¬"""
    identifier = event_data.get("identifier")
    
    # Debouncing
    current_time = time.time()
    if identifier in self._last_product_time:
        if current_time - self._last_product_time[identifier] < 5.0:
            return
    
    self._last_product_time[identifier] = current_time
    
    # DBì—ì„œ ìƒí’ˆ ì¡°íšŒ (barcode ë˜ëŠ” product_id)
    if isinstance(identifier, str) and len(identifier) > 8:
        # ë°”ì½”ë“œë¡œ ì¶”ì •
        product = self.product_dao.get_product_by_barcode(identifier)
    else:
        # product_idë¡œ ì¶”ì •
        product = self.product_dao.get_product_by_id(identifier)
    
    if not product:
        print(f"Unknown product: {identifier}")
        return
    
    # ì¥ë°”êµ¬ë‹ˆì— ì¶”ê°€ (ë‚˜ë¨¸ì§€ ë™ì¼)
    # ...
```

---

#### ğŸ“ `src/database/product_dao.py` - DB ì¡°íšŒ
**ì—­í• **: ìƒí’ˆ ì •ë³´ë¥¼ DBì—ì„œ ê°€ì ¸ì˜¤ê¸°

**í˜„ì¬ êµ¬í˜„:**
```python
class ProductDAO:
    def __init__(self, db_handler):
        self.db = db_handler
    
    def get_product_by_id(self, product_id):
        """product_idë¡œ ìƒí’ˆ ì¡°íšŒ"""
        query = "SELECT * FROM products WHERE id = %s"
        result = self.db.execute_query(query, (product_id,))
        return result[0] if result else None
    
    def get_product_by_barcode(self, barcode):
        """barcodeë¡œ ìƒí’ˆ ì¡°íšŒ"""
        query = "SELECT * FROM products WHERE barcode = %s"
        result = self.db.execute_query(query, (barcode,))
        return result[0] if result else None
```

---

### 3.2 YOLO ëª¨ë¸ í•™ìŠµ (í•„ìš”í•œ ê²½ìš°)

ìƒí’ˆ ì¸ì‹ ì •í™•ë„ë¥¼ ë†’ì´ë ¤ë©´ ì»¤ìŠ¤í…€ ëª¨ë¸ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.

#### ë°ì´í„°ì…‹ ì¤€ë¹„
```bash
# ë””ë ‰í† ë¦¬ êµ¬ì¡°
dataset/
  train/
    images/
      product_001.jpg
      product_002.jpg
    labels/
      product_001.txt  # YOLO í˜•ì‹
      product_002.txt
  val/
    images/
    labels/
```

#### YOLO í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
```python
# scripts/train_product_model.py
from ultralytics import YOLO

# ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
model = YOLO('yolov8n.pt')

# í•™ìŠµ
results = model.train(
    data='dataset/product_data.yaml',
    epochs=100,
    imgsz=640,
    batch=16,
    name='product_recognizer',
    project='models'
)

# ëª¨ë¸ ì €ì¥
model.save('models/product_recognizer/best.pt')
```

#### `dataset/product_data.yaml`
```yaml
train: dataset/train/images
val: dataset/val/images

nc: 50  # ìƒí’ˆ í´ë˜ìŠ¤ ê°œìˆ˜
names:
  0: banana
  1: milk
  2: bread
  3: apple
  # ... 50ê°œê¹Œì§€
```

---

### 3.3 ì‹¤ì‹œê°„ ë””ë²„ê¹… (ì‹œê°í™”)

ìƒí’ˆ ì¸ì‹ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ë ¤ë©´ ì‹œê°í™” ë„êµ¬ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.

#### `src/detectors/product_dl.py`ì— ì‹œê°í™” ì¶”ê°€
```python
def recognize_with_visualization(self, frame):
    """ì¸ì‹ ê²°ê³¼ë¥¼ í”„ë ˆì„ì— ê·¸ë ¤ì„œ ë°˜í™˜"""
    results = self.model.predict(frame, conf=self.threshold, verbose=False)
    
    detected_products = []
    annotated_frame = frame.copy()
    
    if len(results) > 0:
        for box in results[0].boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
            confidence = float(box.conf[0])
            class_id = int(box.cls[0])
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # í…ìŠ¤íŠ¸ í‘œì‹œ
            label = f"Product {class_id}: {confidence:.2f}"
            cv2.putText(annotated_frame, label, (x1, y1-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
            detected_products.append({
                "product_id": class_id,
                "confidence": confidence,
                "bbox": [x1, y1, x2, y2]
            })
    
    return detected_products, annotated_frame
```

#### í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
```python
# test/test_product_recognition.py
import cv2
from detectors.product_dl import ProductRecognizer

recognizer = ProductRecognizer()
cap = cv2.VideoCapture(0)  # ì›¹ìº 

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    products, annotated = recognizer.recognize_with_visualization(frame)
    
    # ê²°ê³¼ ì¶œë ¥
    for p in products:
        print(f"Detected: {p}")
    
    # í™”ë©´ì— í‘œì‹œ
    cv2.imshow('Product Recognition', annotated)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

**ì‹¤í–‰:**
```bash
python test/test_product_recognition.py
```

---

## ìš”ì•½

### ì „ì²´ ì‹¤í–‰ (3ëŒ€ PC)
1. **PC1**: `python src/ai_server.py`
2. **PC2**: `python src/main_hub.py`
3. **PC3**: `python src/cart_camera_app.py` + `python src/cart_ui_app.py`

### PC 1ëŒ€ í…ŒìŠ¤íŠ¸
- ëª¨ë“  IPë¥¼ `127.0.0.1`ë¡œ ì„¤ì •
- 4ê°œ í„°ë¯¸ë„ì—ì„œ ê°ê° ì‹¤í–‰
- ì¹´ë©”ë¼ ì—†ìœ¼ë©´ `test/video_streamer.py` ì‚¬ìš©

### ìƒí’ˆ ì¸ì‹ êµ¬í˜„ ìœ„ì¹˜
1. **`src/detectors/product_dl.py`** â† ê°€ì¥ ì¤‘ìš” (YOLO ëª¨ë¸ ì‚¬ìš©)
2. **`src/ai_server.py`** â† ì¶”ë¡  ë£¨í”„, ì´ë²¤íŠ¸ ì „ì†¡
3. **`src/core/engine.py`** â† ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§, DB ì²˜ë¦¬
4. **`src/database/product_dao.py`** â† DB ì¡°íšŒ

**í•µì‹¬**: `product_dl.py`ì˜ `recognize()` ë©”ì„œë“œë§Œ ìˆ˜ì •í•˜ë©´ ë‚˜ë¨¸ì§€ëŠ” ìë™ìœ¼ë¡œ ì—°ë™ë©ë‹ˆë‹¤!
